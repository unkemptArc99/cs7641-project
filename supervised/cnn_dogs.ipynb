{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LeakyReLU\n",
    "import keras\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['arr_0', 'arr_1', 'arr_2', 'arr_3']\n"
     ]
    }
   ],
   "source": [
    "data = np.load('Dogs_npz.npz')\n",
    "print(data.files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data['arr_0']\n",
    "X_test = data['arr_2']\n",
    "Y_train = data['arr_1']\n",
    "Y_test = data['arr_3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8646, 90, 90, 3)\n",
      "(700, 90, 90, 3)\n",
      "(700, 70)\n",
      "(8646, 70)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)\n",
    "print(Y_train.shape)\n",
    "X_train = X_train/255\n",
    "X_test = X_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = X_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# improve this\n",
    "# activation for hidden layers is not sigmoid and relu because of vanishing gradient problem\n",
    "# relu is the best one for cnns (seems to be standard practice from readings)\n",
    "# for the output layer I chose softmax because it produces a vector of values that sums up to 1.\n",
    "# Where the values indicate the probability of the image belonging to a particular class. \n",
    "# This is the correct one to use for multiclass classification.\n",
    "# relu and sigmoid have the problem of causing dead neurons (0 values for the weights). \n",
    "# so we are using leakyrelu so that \"dead neurons\" will be replaced with very low values.\n",
    "# use activation linear in hidden layers and then leakyrelu as a separate layer\n",
    "model=Sequential()\n",
    "model.add(Conv2D(filters=16, kernel_size=2, padding='same', input_shape=(input_shape, input_shape, 3)))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters=32, kernel_size=2, padding='same'))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters=64, kernel_size=2, padding='same'))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters=128, kernel_size=2, padding='same'))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(512))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(70, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 90, 90, 16)        208       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)   (None, 90, 90, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 45, 45, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 45, 45, 32)        2080      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)   (None, 45, 45, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 22, 22, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 22, 22, 64)        8256      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)   (None, 22, 22, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 11, 11, 128)       32896     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)   (None, 11, 11, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 5, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_3 ( (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 70)                35910     \n",
      "=================================================================\n",
      "Total params: 145,398\n",
      "Trainable params: 145,398\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7946 samples, validate on 700 samples\n",
      "Epoch 1/40\n",
      "7946/7946 [==============================] - 5s 647us/step - loss: 4.1641 - accuracy: 0.0254 - val_loss: 4.0629 - val_accuracy: 0.0329\n",
      "Epoch 2/40\n",
      "7946/7946 [==============================] - 5s 579us/step - loss: 3.9289 - accuracy: 0.0544 - val_loss: 3.7120 - val_accuracy: 0.0814\n",
      "Epoch 3/40\n",
      "7946/7946 [==============================] - 4s 561us/step - loss: 3.7438 - accuracy: 0.0753 - val_loss: 3.6210 - val_accuracy: 0.0743\n",
      "Epoch 4/40\n",
      "7946/7946 [==============================] - 4s 560us/step - loss: 3.6389 - accuracy: 0.0982 - val_loss: 3.4994 - val_accuracy: 0.0914\n",
      "Epoch 5/40\n",
      "7946/7946 [==============================] - 4s 557us/step - loss: 3.5487 - accuracy: 0.1157 - val_loss: 3.4087 - val_accuracy: 0.1414\n",
      "Epoch 6/40\n",
      "7946/7946 [==============================] - 5s 601us/step - loss: 3.4071 - accuracy: 0.1450 - val_loss: 3.2212 - val_accuracy: 0.1543\n",
      "Epoch 7/40\n",
      "7946/7946 [==============================] - 5s 624us/step - loss: 3.2840 - accuracy: 0.1642 - val_loss: 3.1730 - val_accuracy: 0.1786\n",
      "Epoch 8/40\n",
      "7946/7946 [==============================] - 6s 701us/step - loss: 3.1810 - accuracy: 0.1803 - val_loss: 3.0542 - val_accuracy: 0.1771\n",
      "Epoch 9/40\n",
      "7946/7946 [==============================] - 5s 574us/step - loss: 3.1085 - accuracy: 0.1958 - val_loss: 2.9591 - val_accuracy: 0.2057\n",
      "Epoch 10/40\n",
      "7946/7946 [==============================] - 5s 588us/step - loss: 2.9781 - accuracy: 0.2194 - val_loss: 2.9051 - val_accuracy: 0.2143\n",
      "Epoch 11/40\n",
      "7946/7946 [==============================] - 5s 572us/step - loss: 2.9086 - accuracy: 0.2342 - val_loss: 2.7604 - val_accuracy: 0.2643\n",
      "Epoch 12/40\n",
      "7946/7946 [==============================] - 5s 576us/step - loss: 2.8497 - accuracy: 0.2453 - val_loss: 2.7811 - val_accuracy: 0.2386\n",
      "Epoch 13/40\n",
      "7946/7946 [==============================] - 5s 580us/step - loss: 2.7787 - accuracy: 0.2577 - val_loss: 2.7108 - val_accuracy: 0.2729\n",
      "Epoch 14/40\n",
      "7946/7946 [==============================] - 5s 576us/step - loss: 2.7037 - accuracy: 0.2710 - val_loss: 2.5564 - val_accuracy: 0.2871\n",
      "Epoch 15/40\n",
      "7946/7946 [==============================] - 4s 566us/step - loss: 2.6523 - accuracy: 0.2888 - val_loss: 2.5988 - val_accuracy: 0.2871\n",
      "Epoch 16/40\n",
      "7946/7946 [==============================] - 5s 575us/step - loss: 2.6081 - accuracy: 0.2961 - val_loss: 2.5326 - val_accuracy: 0.2957\n",
      "Epoch 17/40\n",
      "7946/7946 [==============================] - 5s 581us/step - loss: 2.5697 - accuracy: 0.3057 - val_loss: 2.5052 - val_accuracy: 0.3114\n",
      "Epoch 18/40\n",
      "7946/7946 [==============================] - 5s 573us/step - loss: 2.4957 - accuracy: 0.3248 - val_loss: 2.4127 - val_accuracy: 0.3100\n",
      "Epoch 19/40\n",
      "7946/7946 [==============================] - 5s 571us/step - loss: 2.4577 - accuracy: 0.3321 - val_loss: 2.3947 - val_accuracy: 0.3329\n",
      "Epoch 20/40\n",
      "7946/7946 [==============================] - 5s 567us/step - loss: 2.4262 - accuracy: 0.3384 - val_loss: 2.3973 - val_accuracy: 0.3286\n",
      "Epoch 21/40\n",
      "7946/7946 [==============================] - 4s 558us/step - loss: 2.3802 - accuracy: 0.3477 - val_loss: 2.3418 - val_accuracy: 0.3457\n",
      "Epoch 22/40\n",
      "7946/7946 [==============================] - 4s 560us/step - loss: 2.3391 - accuracy: 0.3519 - val_loss: 2.1990 - val_accuracy: 0.3786\n",
      "Epoch 23/40\n",
      "7946/7946 [==============================] - 5s 567us/step - loss: 2.3120 - accuracy: 0.3706 - val_loss: 2.2528 - val_accuracy: 0.3686\n",
      "Epoch 24/40\n",
      "7946/7946 [==============================] - 4s 561us/step - loss: 2.2597 - accuracy: 0.3753 - val_loss: 2.2177 - val_accuracy: 0.3914\n",
      "Epoch 25/40\n",
      "7946/7946 [==============================] - 5s 573us/step - loss: 2.2108 - accuracy: 0.3908 - val_loss: 2.2079 - val_accuracy: 0.3700\n",
      "Epoch 26/40\n",
      "7946/7946 [==============================] - 4s 565us/step - loss: 2.1678 - accuracy: 0.3937 - val_loss: 2.2084 - val_accuracy: 0.3786\n",
      "Epoch 27/40\n",
      "7946/7946 [==============================] - 4s 562us/step - loss: 2.1359 - accuracy: 0.4015 - val_loss: 2.0780 - val_accuracy: 0.4057\n",
      "Epoch 28/40\n",
      "7946/7946 [==============================] - 4s 562us/step - loss: 2.1065 - accuracy: 0.4109 - val_loss: 2.0904 - val_accuracy: 0.4100\n",
      "Epoch 29/40\n",
      "7946/7946 [==============================] - 5s 577us/step - loss: 2.0754 - accuracy: 0.4133 - val_loss: 2.0066 - val_accuracy: 0.4243\n",
      "Epoch 30/40\n",
      "7946/7946 [==============================] - 5s 605us/step - loss: 2.0207 - accuracy: 0.4279 - val_loss: 2.0563 - val_accuracy: 0.4200\n",
      "Epoch 31/40\n",
      "7946/7946 [==============================] - 5s 593us/step - loss: 2.0218 - accuracy: 0.4334 - val_loss: 2.0405 - val_accuracy: 0.4143\n",
      "Epoch 32/40\n",
      "7946/7946 [==============================] - 5s 604us/step - loss: 1.9626 - accuracy: 0.4395 - val_loss: 2.1411 - val_accuracy: 0.3843\n",
      "Epoch 33/40\n",
      "7946/7946 [==============================] - 5s 567us/step - loss: 1.9388 - accuracy: 0.4498 - val_loss: 1.9743 - val_accuracy: 0.4400\n",
      "Epoch 34/40\n",
      "7946/7946 [==============================] - 5s 590us/step - loss: 1.9079 - accuracy: 0.4580 - val_loss: 2.0364 - val_accuracy: 0.4329\n",
      "Epoch 35/40\n",
      "7946/7946 [==============================] - 5s 586us/step - loss: 1.8955 - accuracy: 0.4591 - val_loss: 2.0055 - val_accuracy: 0.4271\n",
      "Epoch 36/40\n",
      "7946/7946 [==============================] - 5s 592us/step - loss: 1.8408 - accuracy: 0.4680 - val_loss: 2.0184 - val_accuracy: 0.4186\n",
      "Epoch 37/40\n",
      "7946/7946 [==============================] - 5s 591us/step - loss: 1.8210 - accuracy: 0.4792 - val_loss: 1.9142 - val_accuracy: 0.4314\n",
      "Epoch 38/40\n",
      "7946/7946 [==============================] - 5s 580us/step - loss: 1.7867 - accuracy: 0.4872 - val_loss: 1.9581 - val_accuracy: 0.4471\n",
      "Epoch 39/40\n",
      "7946/7946 [==============================] - 5s 618us/step - loss: 1.7686 - accuracy: 0.4976 - val_loss: 1.8977 - val_accuracy: 0.4514\n",
      "Epoch 40/40\n",
      "7946/7946 [==============================] - 6s 726us/step - loss: 1.7412 - accuracy: 0.4908 - val_loss: 1.8844 - val_accuracy: 0.4500\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train, epochs=40, validation_split=0.08096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_hat = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_hat_test = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(Y_test.argmax(axis=1), Y_hat_test.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prath\\anaconda\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\prath\\anaconda\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\prath\\anaconda\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "cr = classification_report(Y_test.argmax(axis=1), Y_hat_test.argmax(axis=1), output_dict=True)\n",
    "# it gives you a warning because some labels are never predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(cm)\n",
    "# print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(cr).transpose()\n",
    "df.to_csv(r'C:\\Users\\prath\\Downloads\\Machine_Learning\\Dogs\\classification_report.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # transfer learning using vgg16 and resnet50\n",
    "# # i think we should try other models and see which ones provide the best results\n",
    "# from keras.applications.resnet50 import ResNet50\n",
    "# from keras.applications.vgg16 import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_model = tf.keras.applications.VGG16(input_shape=((224,224,3)),include_top=False)\n",
    "# base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_batch, label_batch = next(iter(np.load(X_train)))\n",
    "# feature_batch = base_model(image_batch)\n",
    "# print(feature_batch.shape)\n",
    "# # model_vgg16.add()\n",
    "# # model_vgg16.add(GlobalAveragePooling2D(input_shape=(224,224,3)))\n",
    "# # model_vgg16.add(Dense(70, activation='softmax'))\n",
    "# # model_vgg16.summary()\n",
    "# model_vgg16.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
